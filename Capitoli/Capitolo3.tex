% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../Tesi.tex
% !TEX spellcheck = it-IT

%************************************************

%************************************************

Il clustering di pagine Web non è un nuovo ambito di ricerca. Nei diversi anni si sono susseguite in letteratura una serie di tecniche e metodologie per il raggruppamento ed il reperimento di pagine Web~\cite{}. 


Tuttavia gli sforzi si sono concentrati prevalentemente su pagine provenienti da diversi siti Web. Relativamente poco è stato il lavoro svolto sul clustering di un specifico sito di una determinata organizzazione. \color{red}Questo fattore, CHE FATTORE \color{black}influisce sulla semantica degli hyperlink all'interno di una pagina Web, questi hanno infatti significati diversi in relazione al domino di destinazione. Se la pagina puntata si trova nello stesso dominio, il collegamento avrà funzione di organizzazione dei contenuti, mentre se il collegamento punta ad una pagina esterna, questo sarà indirizzato alla conferma del contenuto mostrato e presenterà molto probabilmente argomenti simili~\cite{}. 

In \cite{}

%Scoprire correlazioni nelle pagine Web può essere effettuato attraverso l'analisi del contenuto testuale e/o HTML delle pagine web. Compito degli algoritmi di clustering che analizzano il solo contenuto testuale %delle pagine web è quello di analizzare la distribuzione dei termini delle singole pagine web e raggruppare le stesse in funzione dei topic descritti. I cluster così ottenuti sono composti da pagine non necessariamente collegate tra loro, ma trattanti simili argomenti. 

%Gli algoritmi di clustering che analizzano la struttura HTML delle pagine web possono sfruttare due importanti proprietà: \textit{i) } proprietà visuali, ossia come una pagina è renderizzata da un web browser; \textit{ii) } proprietà strutturali, ossia la struttura dei tag HTML di cui una pagina web si compone. Compito degli algoritmi di clustering che ricadono in questa tipologia è  scoprire pattern di tag HTML e raggruppare le pagine web in funzione dei pattern estratti.

%Gli svantaggi di queste metodologie derivano dall'eterogeneità del Web e dalle assunzioni di partenza. Infatti la struttura a grafo fortemente connessa di un sito web può non bastare a codificare tutte le informazioni necessarie. Inoltre le assunzioni di indipendenza dei documenti nella collezione e dei termini nel documento non sono sempre verificate, soprattutto nel contesto del Web. 

Gli algoritmi di clustering di pagine web possono essere classificati in tre grandi categorie in base alle informazioni che questi utilizzano per raggruppare le pagine web:

%Le tecniche diffuse in letteratura possono dunque essere raggruppate in base alle informazioni che considerano, ovvero se la semantica, la struttura o l'utilizzo di una pagina Web.
\begin{itemize}
\item \textbf{Algoritmi di clustering basati sul contenuto testuale}. Ricadono in questa categoria gli algoritmi che analizzano la distribuzione dei termini delle singole pagine web e raggruppano le stesse in funzione dei topic descritti. I cluster così ottenuti sono composti da pagine non necessariamente collegate tra loro, ma trattanti  argomenti simili. 
\color{red}
In [x] gli autori propongono X. Cosa fa. Vantaggi/Svantaggi
\color{green}
Come proposto in \cite{Cooley03}, questo approccio suggerisce l'utilizzo di informazioni semantiche per migliorare il processo di estrazione, necessitano quindi meta-informazioni aggiuntive sulla struttura e sulla gerarchia. Il contenuto può essere utilizzato per rappresentare la distribuzione dei termini o possono essere estratte informazioni aggiuntive attraverso l'analisi dei metadati o sapendo se è stato utilizzato un particolare tool per la gestione del sito.
\color{black}

\item \textbf{Algoritmi di clustering basati sul Web Log}. \color{red} Possono essere estratti pattern di utilizzo dai Web log ed essere utilizzati per predire il comportamento futuro degli utenti, per raggruppare le pagine in base agli interessi comuni o per pesare gli archi del grafo, in modo da combinare diversi approcci \cite{Shahabi97}. Lavori recenti si stanno dirigendo sempre più sullo Web Usage Mining, in modo da personalizzare le risposte alle query immesse nei motori di ricerca~\cite{Crabtree06}.
\color{black}
\item \textbf{Algoritmi di clustering basati sulla struttura HTML}.\color{red}
La struttura interna alle pagine Web può essere analizzata per scovare pattern ricorrenti nei tag. Infatti le pagine HTML presentano tag innestati in maniera gerarchica che formano una struttura ad albero. Questa può essere utilizzata per costruire una funzione di similarità. 

 Gli algoritmi di clustering che analizzano la struttura HTML delle pagine web possono sfruttare due importanti proprietà: \textit{i) } proprietà visuali, ossia come una pagina è renderizzata da un web browser; \textit{ii) } proprietà strutturali, ossia la struttura dei tag HTML di cui una pagina web si compone. Compito degli algoritmi di clustering che ricadono in questa tipologia è  scoprire pattern di tag HTML e raggruppare le pagine web in funzione dei pattern estratti.

QUI PUOI CITARE \url{http://www.cs.man.ac.uk/~pmissier/docs/sdarticle.pdf}

\item \textbf{Algoritmi di clustering basati sulla struttura ad hyperlink}. Come introdotto precedentemente, la struttura del Web suggerisce l'applicazione di analisi del grafo ricavato dagli hyperlink. Soluzioni proposte \cite{Luxburg07} si basano sul dividere tale struttura in sotto-grafi, tramite una funzione che minimizza il numero di archi tra cluster e massimizza il numero degli archi tra i nodi di un cluster. In questo caso il clustering delle pagine web diventa il partizionamento del grafo.  

METTERE RIFERIMENTO A TIM 
\end{itemize}
%\begin{itemize}

%\item Come proposto in \cite{Cooley03}, questo approccio suggerisce l'utilizzo di informazioni semantiche per migliorare il processo di estrazione, necessitano quindi meta-informazioni aggiuntive sulla struttura e sulla gerarchia. Il contenuto può essere utilizzato per rappresentare la distribuzione dei termini o possono essere estratte informazioni aggiuntive attraverso l'analisi dei metadati o sapendo se è stato utilizzato un particolare tool per la gestione del sito.

%\item La struttura interna alle pagine Web può essere analizzata per scovare pattern ricorrenti nei tag. Infatti le pagine HTML presentano tag innestati in maniera gerarchica che formano una struttura ad albero. Questa può essere utilizzata per costruire una funzione di similarità. 

%\item Come introdotto precedentemente, la struttura del Web suggerisce l'applicazione di analisi del grafo ricavato dagli hyperlink. Soluzioni proposte \cite{Luxburg07} si basano sul dividere tale struttura in sotto-grafi, tramite una funzione che minimizza il numero di archi tra cluster e massimizza il numero degli archi tra i nodi di un cluster. In questo caso il clustering delle pagine web diventa il partizionamento del grafo. 

%\item Possono essere estratti pattern di utilizzo dai Web log ed essere utilizzati per predire il comportamento futuro degli utenti, per raggruppare le pagine in base agli interessi comuni o per pesare gli archi del grafo, in modo da combinare diversi approcci \cite{Shahabi97}. Lavori recenti si stanno dirigendo sempre più sullo Web Usage Mining, in modo da personalizzare le risposte alle query immesse nei motori di ricerca~\cite{Crabtree06}.
%\end{itemize}

\section{SiteMap Generator}
Molto del lavoro svolto sull'argomento si focalizza sul clustering di pagine web provenienti da siti diversi basandosi su di un approccio specifico piuttosto che un altro. Un caso interessante è il sistema SiteMap Generator (SMG)~\cite{Lin11} che mette in pratica un approccio ibrido, analizzando sia la struttura interna che quella esterna. Infatti esso divide la pagina in blocchi, li classifica sulla base della loro rilevanza per costruire la sitemap, ed infine analizza i collegamenti che ci sono fra blocchi per identificare i blocchi più autorevoli. In seguito i blocchi con alta frequenza di occorrenza e un alto valore hub, ottenuto nell'ultima fase tramite l'algoritmo HITS, vengono utilizzati per generare la sitemap.
\\
In SMG l'obiettivo è dunque la costruzione della sitemap, estraendo dalla struttura delle pagine di uno stesso dominio gli hyperlink necessari. Questo è un approccio particolare in quanto viene introdotto il concetto di inlink ed outlink fra blocchi piuttosto che tra pagine. 
\\
Anche se lo scopo è diverso, è utile notare che come in Url2vec, in SMG vengono ispezionate solo pagine all'interno di uno stesso dominio e vengono utilizzati algoritmi derivanti da svariate aree applicative, come la biologia o la già citata variante dell'algoritmo HITS \cite{Kleinberg99}

\section{DeepWalk}
ANALISI Grafo web attraverso random walk

\url{http://yonatanbisk.com/papers/2012-CIKM.pdf} 
Nell'ambito della Social Networks Analysis, DeepWalk \cite{Perozzi14} propone una metodologia interessante. Dato un grafo, vengono generati Random Walk di piccola lunghezza. Questi vengono poi trattati come frasi, e applicando tecniche di Natural Language Processing viene stimata la verosimiglianza che specifiche sequenze di parole (in questo caso i nodi del grafo) appaiano nel corpus, ovvero l'insieme dei Random Walk generati. Queste vengono poi rappresentate in uno spazio vettoriale.
\\
Questo approccio viene applicato nell'ambito delle reti sociali per l'identificazione di gruppi sociali correlati, tecnica che viene chiamata ''Community Detection''.
\\
In Url2vec l'obiettivo rimane quello di raggruppare le pagine Web in cluster, quindi la sostanziale differenza riguarda l'informazione presente all'interno del nodo del grafo di interesse. Si tratta appunto di una pagina Web, che comprende informazioni di tipo testuale. 
